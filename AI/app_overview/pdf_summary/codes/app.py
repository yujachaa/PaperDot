import warnings
import os
from pdf_summary.codes.crawler import download_pdf  # ìˆ˜ì •ëœ download_pdf ì‚¬ìš©
from contextlib import asynccontextmanager
import uvicorn
import pickle
from dotenv import load_dotenv
from fastapi import FastAPI, Query, HTTPException, Depends
from pydantic import BaseModel
import numpy as np
import re
import urllib.parse
from fastapi.middleware.cors import CORSMiddleware

from langchain_community.document_loaders import PDFPlumberLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from operator import itemgetter
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables import chain
from langchain_core.documents import Document
from langchain_text_splitters import MarkdownHeaderTextSplitter
from langchain.prompts import PromptTemplate
from elasticsearch import Elasticsearch
from langchain import hub
import openai
import pymupdf4llm
import asyncio
from concurrent.futures import ThreadPoolExecutor
from selenium import webdriver
from queue import Queue
from threading import Lock

import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# WebDriver í’€ í´ë˜ìŠ¤ ì •ì˜
class WebDriverPool:
    def __init__(self, max_size=5):
        self.pool = Queue(max_size)
        self.lock = Lock()
        for _ in range(max_size):
            driver = create_driver()
            self.pool.put(driver)
            logger.info(f"WebDriver ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ. í˜„ì¬ í’€ í¬ê¸°: {self.pool.qsize()}")

    def get_driver(self):
        driver = self.pool.get()
        logger.info(f"WebDriver ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜´. í˜„ì¬ í’€ í¬ê¸°: {self.pool.qsize()}")
        return driver

    def return_driver(self, driver):
        self.pool.put(driver)
        logger.info(f"WebDriver ì¸ìŠ¤í„´ìŠ¤ í’€ì— ë°˜í™˜ë¨. í˜„ì¬ í’€ í¬ê¸°: {self.pool.qsize()}")

    def close_all(self):
        while not self.pool.empty():
            driver = self.pool.get()
            driver.quit()
            logger.info(f"WebDriver ì¸ìŠ¤í„´ìŠ¤ ì¢…ë£Œë¨. ë‚¨ì€ í’€ í¬ê¸°: {self.pool.qsize()}")

# WebDriver ìƒì„± í•¨ìˆ˜
def create_driver():
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.chrome.options import Options

    current_dir = os.path.dirname(os.path.abspath(__file__))
    env_path = os.path.join(current_dir, "../../config/.env")
    load_dotenv(dotenv_path=env_path)
    CHROME_PATH = os.path.join(current_dir, os.getenv('LINUX_CHROME_PATH'))
    DRIVER_PATH = os.path.join(current_dir, os.getenv('LINUX_DRIVER_PATH'))

    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('--remote-debugging-port=9222')
    options.add_argument('--log-level=3')
    options.add_argument('--disable-blink-features=AutomationControlled')
    options.binary_location = CHROME_PATH
    options.add_argument('--disable-extensions')
    options.add_argument('--disable-infobars')
    options.add_argument('--disable-browser-side-navigation')
    options.add_argument('--disable-features=VizDisplayCompositor')

    service = Service(DRIVER_PATH)
    driver = webdriver.Chrome(service=service, options=options)
    return driver

# WebDriver í’€ ì´ˆê¸°í™” (ìµœëŒ€ 5ê°œ)
driver_pool = WebDriverPool(max_size=5)

current_dir = os.path.dirname(os.path.abspath(__file__))
env_path = os.path.join(current_dir, "../config/.env")

# Define paths
MAPPING_PICKLE_FILE = os.path.join(current_dir, "../models/doc_id_index_mapping.pkl")
PAPER_STORAGE_PATH = os.path.join(current_dir, "../datas/")

load_dotenv(dotenv_path=env_path)

openai.api_key = os.getenv("OPENAI_API_KEY")

# Elasticsearch ì„¤ì •
ES_HOST = os.getenv('ES_HOST')  # ì˜ˆ: 'localhost' ë˜ëŠ” 'your-ec2-public-dns'
ES_PORT = os.getenv('ES_PORT')  # ê¸°ë³¸ í¬íŠ¸; ë‹¤ë¥¼ ê²½ìš° ë³€ê²½
ES_USER = os.getenv('ES_USER')  # ì¸ì¦ì´ í•„ìš”í•œ ê²½ìš°
ES_PASSWORD = os.getenv('ES_PASSWORD')  # ì¸ì¦ì´ í•„ìš”í•œ ê²½ìš°
ES_APIKEY = os.getenv('ES_APIKEY')
INDEX_NAME = 'papers'

mapper = None
reverse_mapper = None
llm = None

# CORS ì„¤ì • ì¶”ê°€
origins = [
    "http://localhost:5173",
    "https://localhost:5173",  # ì˜ˆë¥¼ ë“¤ì–´ ë¦¬ì•¡íŠ¸ ë¡œì»¬ ì„œë²„
    "https://j11b208.p.ssafy.io",  # ì‹¤ì œë¡œ ì‚¬ìš©í•˜ëŠ” ë„ë©”ì¸ ì¶”ê°€
]

headers_to_split_on = [
    ("#", "Header 1"),
    ("##", "Header 2"),
    ("###", "Header 3"),
]

prompt_template = """
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ì½ê³  ë˜ë„ë¡ í•œê¸€ë¡œ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”. ìš”ì•½ ì‹œì—ëŠ” markdown íƒœê·¸ë¥¼ ì ê·¹ í™œìš©í•´ì£¼ì„¸ìš”. '#' í—¤ë”ê°€ ìˆë‹¤ë©´ ê° ë¬¸ë‹¨ì— ì–´ìš¸ë¦¬ëŠ” ì´ëª¨ì§€ë¥¼ í—¤ë”ì— í¬í•¨í•´ ê¾¸ë©°ì£¼ì„¸ìš”.

"{text}"

ìš”ì•½:
"""

PROMPT = PromptTemplate(template=prompt_template, input_variables=["text"])

def load_mapping_pickle_data(pickle_file):
    """
    í”¼í´ íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    if not os.path.exists(pickle_file):
        logger.error(f"í”¼í´ íŒŒì¼ {pickle_file}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        raise FileNotFoundError(f"í”¼í´ íŒŒì¼ {pickle_file}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    with open(pickle_file, 'rb') as f:
        data = pickle.load(f)
    logger.info(f"í”¼í´ íŒŒì¼ {pickle_file} ë¡œë“œ ì™„ë£Œ.")
    return data

def create_internal_links(markdown_text):
    header_pattern = re.compile(r'^(#)\s+(.*)', re.MULTILINE)
    headers = header_pattern.findall(markdown_text)
    
    links = []
    for i, header in enumerate(headers, start=1):
        hashes, header_text = header
        anchor = re.sub(r'\s+', '-', header_text.strip()).lower()
        anchor = re.sub(r'[^\w\-\u2600-\u27BF\u1F300-\u1FAFF\u1F900-\u1F9FF\u1F600-\u1F64F]', '', anchor)
        link = f"[{i}. {header_text}](#{anchor})"
        links.append(link)
    links = "<br>".join(links)
    return links

def get_pdf(paper_path, paper_id, reverse_mapper, driver):
    doc_id = reverse_mapper.get(paper_id)
    if not doc_id:
        logger.error(f"paper_id {paper_id}ì— ëŒ€í•œ doc_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        raise ValueError(f"paper_id {paper_id}ì— ëŒ€í•œ doc_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    logger.info(f"Paper ID: {paper_id} maps to Doc ID: {doc_id}")
    
    if not os.path.exists(paper_path):
        logger.info(f"Paper ID: {paper_id}ì— í•´ë‹¹í•˜ëŠ” PDFê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œ ì‹œì‘.")
        download_pdf(doc_id, paper_path, driver)
    else:
        logger.info(f"Paper ID: {paper_id}ì— í•´ë‹¹í•˜ëŠ” PDFê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
    
    with open(paper_path, "rb") as f:
        pdf_document = f.read()
    return pdf_document

# Elasticsearch í´ë¼ì´ì–¸íŠ¸ ìƒì„±
def create_es_client(host=ES_HOST, port=ES_PORT, user=ES_USER, password=ES_PASSWORD):
    """
    Elasticsearch í´ë¼ì´ì–¸íŠ¸ì— ì—°ê²°í•©ë‹ˆë‹¤.
    """
    try:
        if user and password:
            es = Elasticsearch(
                f"http://{host}:{port}",
                basic_auth=(user, password),
                request_timeout=60,
            )
        else:
            es = Elasticsearch(
                f"http://{host}:{port}",
                request_timeout=60,
            )
        # ì—°ê²° í™•ì¸
        if not es.ping():
            logger.error("Elasticsearch ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            raise ValueError("Elasticsearch ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        logger.info("Elasticsearchì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return es
    except Exception as e:
        logger.error(f"Elasticsearch ì—°ê²° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise e

class QueryResponse(BaseModel):
    answer: str
    model: int

# FastAPI ìƒíƒœ í´ë˜ìŠ¤ ì •ì˜
class AppState:
    def __init__(self):
        self.mapper = load_mapping_pickle_data(MAPPING_PICKLE_FILE)
        self.reverse_mapper = {v: k for k, v in self.mapper.items()}
        self.llm = ChatOpenAI(
            model_name="gpt-4o-mini",
            streaming=True,
            temperature=0,
        )
        self.es = create_es_client()

# ì˜ì¡´ì„± ì£¼ì… í•¨ìˆ˜
async def get_app_state():
    return app.state

# FastAPI lifespan ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì‹¤í–‰ë  ì´ˆê¸°í™” ë¡œì§
    logger.info("Initializing embedding system...")
    app.state = AppState()
    
    # lifespanì— ì§„ì… (ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘)
    yield
    
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ì‹¤í–‰ë  ì •ë¦¬ ì‘ì—…
    logger.info("Shutting down...")
    driver_pool.close_all()

# FastAPI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±, lifespan ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì‚¬ìš©
app = FastAPI(lifespan=lifespan)
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,  # í—ˆìš©í•  ë„ë©”ì¸
    allow_credentials=True,
    allow_methods=["*"],  # ëª¨ë“  ë©”ì„œë“œ í—ˆìš© (GET, POST ë“±)
    allow_headers=["*"],  # ëª¨ë“  í—¤ë” í—ˆìš©
)

def agent_pipeline(paper_path, paper_id, state: AppState):
    driver = driver_pool.get_driver()
    try:
        pdf_document = get_pdf(paper_path, paper_id, state.reverse_mapper, driver)

        markdown_document = pymupdf4llm.to_markdown(paper_path)

        markdown_splitter = MarkdownHeaderTextSplitter(
            headers_to_split_on=headers_to_split_on,
            strip_headers=False, # í—¤ë” ì œê±° off
        )

        md_header_splits = markdown_splitter.split_text(markdown_document)

        md_header_splits = [section.page_content for section in md_header_splits]

        # ì´ë¯¸ state.llmì´ ì´ˆê¸°í™”ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì¬ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ
        llm = state.llm

        map_chain = PROMPT | llm | StrOutputParser()

        doc_summaries = map_chain.batch(md_header_splits)

        doc_summaries = '\n\n'.join(doc_summaries)

        internal_links = create_internal_links(doc_summaries)

        toc_markdown = f"# ëª©ì°¨\n\n{internal_links}\n\n"
        final_markdown = toc_markdown + '\n --- \n' + doc_summaries

        logger.info(f"Paper ID: {paper_id} ìš”ì•½ ì™„ë£Œ.")
        return final_markdown
    finally:
        driver_pool.return_driver(driver)

# ThreadPoolExecutor ì´ˆê¸°í™”
executor = ThreadPoolExecutor(max_workers=5)

async def agent_pipeline_async(paper_path, paper_id, state: AppState):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(executor, agent_pipeline, paper_path, paper_id, state)

@app.get("/summary")
async def summary_paper(
    paper_id: str = Query(..., description="Paper ID to search"),
    gen: bool = Query(..., description="RE:generate flag"),
    state: AppState = Depends(get_app_state)
):
    """
    ìš”ì•½ API ì—”ë“œí¬ì¸íŠ¸ë¡œ, GET ìš”ì²­ìœ¼ë¡œ ì „ë‹¬ëœ idì— ëŒ€í•´ ìš”ì•½ëœ markdown ë°˜í™˜.
    """
    es = state.es

    try:
        res = es.get(index=INDEX_NAME, id=paper_id, ignore=404)
    except Exception as e:
        logger.error(f"Elasticsearch ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"Elasticsearch ì˜¤ë¥˜: {e}")

    if res['found']:
        doc = res['_source']
        if 'overview' in doc and doc['overview'] and not gen:
            logger.info(f"Paper ID: {paper_id}ì˜ ê¸°ì¡´ ìš”ì•½ ë°˜í™˜.")
            return {"results": doc['overview'], "model": 0}
        else:
            paper_path = os.path.join(PAPER_STORAGE_PATH, f"{paper_id}.pdf")
            try:
                results = await agent_pipeline_async(paper_path, paper_id, state)
                es.update(index=INDEX_NAME, id=paper_id, body={"doc": {"overview": results}})
                logger.info(f"Paper ID: {paper_id}ì˜ ìš”ì•½ ìƒì„± ë° Elasticsearch ì—…ë°ì´íŠ¸ ì™„ë£Œ.")
                return {"results": results, "model": 1}
            except Exception as e:
                logger.error(f"ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
                raise HTTPException(status_code=500, detail=f"ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
    else:
        logger.warning(f"Paper ID: {paper_id}ì„ Elasticsearchì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        results = "\n\n ## ğŸ™ ì¬ìš”ì•½ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”. ğŸ™"
        return {"results": results, "model": 0}

def main():
    """
    í¸ì˜ì„±ì„ ìœ„í•œ main í•¨ìˆ˜. uvicornì„ ì‚¬ìš©í•´ FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰.
    """
    uvicorn.run("app:app", host="0.0.0.0", port=3333, reload=True)

if __name__ == "__main__":
    try:
        # ê¸°ì¡´ ì½”ë“œ ì‹¤í–‰
        main()  # ì£¼ ì‹¤í–‰ ì½”ë“œ
    except Exception as e:
        logger.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
