# app.py
import warnings
import os
from pdf_summary.codes.crawler import download_pdf  # ìˆ˜ì •ëœ download_pdf ì‚¬ìš©
from contextlib import asynccontextmanager
import uvicorn
import pickle
from dotenv import load_dotenv
from fastapi import FastAPI, Query, HTTPException, Depends
from pydantic import BaseModel
import numpy as np
import re
import urllib.parse
from fastapi.middleware.cors import CORSMiddleware

from langchain_community.document_loaders import PDFPlumberLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from operator import itemgetter
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables import chain
from langchain_core.documents import Document
from langchain_text_splitters import MarkdownHeaderTextSplitter
from langchain.prompts import PromptTemplate
from elasticsearch import Elasticsearch
from langchain import hub
import openai
import pymupdf4llm
import asyncio
from concurrent.futures import ThreadPoolExecutor

from pdf_summary.codes import driver_pool  # WebDriverPoolì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

# Define paths
current_dir = os.path.dirname(os.path.abspath(__file__))
env_path = os.path.join(current_dir, "../../config/.env")
MAPPING_PICKLE_FILE = os.path.join(current_dir, "../models/doc_id_index_mapping.pkl")
PAPER_STORAGE_PATH = os.path.join(current_dir, "../datas/")

load_dotenv(dotenv_path=env_path)
openai.api_key = os.getenv("OPENAI_API_KEY")

# Elasticsearch ì„¤ì •
ES_HOST = os.getenv('ES_HOST')  # ì˜ˆ: 'localhost' ë˜ëŠ” 'your-ec2-public-dns'
ES_PORT = os.getenv('ES_PORT')  # ê¸°ë³¸ í¬íŠ¸; ë‹¤ë¥¼ ê²½ìš° ë³€ê²½
ES_USER = os.getenv('ES_USER')  # ì¸ì¦ì´ í•„ìš”í•œ ê²½ìš°
ES_PASSWORD = os.getenv('ES_PASSWORD')  # ì¸ì¦ì´ í•„ìš”í•œ ê²½ìš°
ES_APIKEY = os.getenv('ES_APIKEY')
INDEX_NAME = 'papers'

# CORS ì„¤ì • ì¶”ê°€
origins = [
    "http://localhost:5173",
    "https://localhost:5173",  # ì˜ˆë¥¼ ë“¤ì–´ ë¦¬ì•¡íŠ¸ ë¡œì»¬ ì„œë²„
    "https://j11b208.p.ssafy.io",  # ì‹¤ì œë¡œ ì‚¬ìš©í•˜ëŠ” ë„ë©”ì¸ ì¶”ê°€
]

headers_to_split_on = [
    ("#", "Header 1"),
    ("##", "Header 2"),
    ("###", "Header 3"),
]

prompt_template = """
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ì½ê³  ë˜ë„ë¡ í•œê¸€ë¡œ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”. ìš”ì•½ ì‹œì—ëŠ” markdown íƒœê·¸ë¥¼ ì ê·¹ í™œìš©í•´ì£¼ì„¸ìš”. '#' í—¤ë”ê°€ ìˆë‹¤ë©´ ê° ë¬¸ë‹¨ì— ì–´ìš¸ë¦¬ëŠ” ì´ëª¨ì§€ë¥¼ í—¤ë”ì— í¬í•¨í•´ ê¾¸ë©°ì£¼ì„¸ìš”.

"{text}"

ìš”ì•½:
"""

PROMPT = PromptTemplate(template=prompt_template, input_variables=["text"])

def load_mapping_pickle_data(pickle_file):
    """
    í”¼í´ íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    if not os.path.exists(pickle_file):
        raise FileNotFoundError(f"í”¼í´ íŒŒì¼ {pickle_file}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    with open(pickle_file, 'rb') as f:
        data = pickle.load(f)
    return data

def create_internal_links(markdown_text):
    header_pattern = re.compile(r'^(#)\s+(.*)', re.MULTILINE)
    headers = header_pattern.findall(markdown_text)
    
    links = []
    for i, header in enumerate(headers, start=1):
        hashes, header_text = header
        anchor = re.sub(r'\s+', '-', header_text.strip()).lower()
        anchor = re.sub(r'[^\w\-\u2600-\u27BF\u1F300-\u1FAFF\u1F900-\u1F9FF\u1F600-\u1F64F]', '', anchor)
        link = f"[{i}. {header_text}](#{anchor})"
        links.append(link)
    links = "<br>".join(links)
    return links

def get_pdf(paper_path, paper_id, reverse_mapper):
    if not os.path.exists(paper_path):
        download_pdf(reverse_mapper[int(paper_id)], paper_path)
    with open(paper_path, "rb") as f:
        pdf_document = f.read()
    return pdf_document

# Elasticsearch í´ë¼ì´ì–¸íŠ¸ ìƒì„±
def create_es_client(host=ES_HOST, port=ES_PORT, user=ES_USER, password=ES_PASSWORD):
    """
    Elasticsearch í´ë¼ì´ì–¸íŠ¸ì— ì—°ê²°í•©ë‹ˆë‹¤.
    """
    if user and password:
        es = Elasticsearch(
            f"http://{host}:{port}",
            basic_auth=(user, password),
            request_timeout=60,
        )
    else:
        es = Elasticsearch(
            f"http://{host}:{port}",
            request_timeout=60,
        )
    # ì—°ê²° í™•ì¸
    if not es.ping():
        raise ValueError("Elasticsearch ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    print("Elasticsearchì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return es

class QueryResponse(BaseModel):
    answer: str
    model: int

# FastAPI ìƒíƒœ í´ë˜ìŠ¤ ì •ì˜
class AppState:
    def __init__(self):
        self.mapper = load_mapping_pickle_data(MAPPING_PICKLE_FILE)
        self.reverse_mapper = {v: k for k, v in self.mapper.items()}
        self.llm = ChatOpenAI(
            model_name="gpt-4o-mini",
            streaming=True,
            temperature=0,
        )
        self.es = create_es_client()

# ì˜ì¡´ì„± ì£¼ì… í•¨ìˆ˜
async def get_app_state():
    return app.state

# ThreadPoolExecutor ì´ˆê¸°í™”
executor = ThreadPoolExecutor(max_workers=5)

def agent_pipeline(paper_path, paper_id, state: AppState):
    pdf_document = get_pdf(paper_path, paper_id, state.reverse_mapper)

    markdown_document = pymupdf4llm.to_markdown(paper_path)

    markdown_splitter = MarkdownHeaderTextSplitter(
        headers_to_split_on=headers_to_split_on,
        strip_headers=False, # í—¤ë” ì œê±° off
    )

    md_header_splits = markdown_splitter.split_text(markdown_document)

    md_header_splits = [section.page_content for section in md_header_splits]

    # ì´ë¯¸ state.llmì´ ì´ˆê¸°í™”ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì¬ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ
    llm = state.llm

    map_chain = PROMPT | llm | StrOutputParser()

    doc_summaries = map_chain.batch(md_header_splits)

    doc_summaries = '\n\n'.join(doc_summaries)

    internal_links = create_internal_links(doc_summaries)

    toc_markdown = f"# ëª©ì°¨\n\n{internal_links}\n\n"
    final_markdown = toc_markdown + '\n --- \n' + doc_summaries

    return final_markdown

async def agent_pipeline_async(paper_path, paper_id, state: AppState):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(executor, agent_pipeline, paper_path, paper_id, state)

# FastAPI lifespan ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì‹¤í–‰ë  ì´ˆê¸°í™” ë¡œì§
    print("Initializing embedding system...")
    app.state = AppState()
    
    # lifespanì— ì§„ì… (ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘)
    yield
    
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ì‹¤í–‰ë  ì •ë¦¬ ì‘ì—…
    print("Shutting down...")
    driver_pool.close_all()

# FastAPI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±, lifespan ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì‚¬ìš©
app = FastAPI(lifespan=lifespan)
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,  # í—ˆìš©í•  ë„ë©”ì¸
    allow_credentials=True,
    allow_methods=["*"],  # ëª¨ë“  ë©”ì„œë“œ í—ˆìš© (GET, POST ë“±)
    allow_headers=["*"],  # ëª¨ë“  í—¤ë” í—ˆìš©
)

@app.get("/summary")
async def summary_paper(
    paper_id: str = Query(..., description="Paper ID to search"),
    gen: bool = Query(..., description="RE:generate flag"),
    state: AppState = Depends(get_app_state)
):
    """
    ìš”ì•½ API ì—”ë“œí¬ì¸íŠ¸ë¡œ, GET ìš”ì²­ìœ¼ë¡œ ì „ë‹¬ëœ idì— ëŒ€í•´ ìš”ì•½ëœ markdown ë°˜í™˜.
    """
    es = state.es

    try:
        res = es.get(index=INDEX_NAME, id=paper_id, ignore=404)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Elasticsearch ì˜¤ë¥˜: {e}")
    
    print('ì²´í¬1')

    if res['found']:
        doc = res['_source']
        if 'overview' in doc and doc['overview'] and not gen:
            print('ì²´í¬2')
            return {"results": doc['overview'], "model": 0}
        else:
            paper_path = f"{PAPER_STORAGE_PATH}{paper_id}.pdf"
            try:
                results = await agent_pipeline_async(paper_path, paper_id, state)
                print('ì²´í¬3')
                es.update(index=INDEX_NAME, id=paper_id, body={"doc": {"overview": results}})
                return {"results": results, "model": 1}
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
    else:
        results = "\n\n ## ğŸ™ ì¬ìš”ì•½ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”. ğŸ™"
        return {"results": results, "model": 0}

def main():
    """
    í¸ì˜ì„±ì„ ìœ„í•œ main í•¨ìˆ˜. uvicornì„ ì‚¬ìš©í•´ FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰.
    """
    uvicorn.run("app:app", host="0.0.0.0", port=3333, reload=True)

if __name__ == "__main__":
    try:
        # ê¸°ì¡´ ì½”ë“œ ì‹¤í–‰
        main()  # ì£¼ ì‹¤í–‰ ì½”ë“œ
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
